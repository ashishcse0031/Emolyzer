{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_images(dataset, n_images, samples_per_image):\n    output = np.zeros((32 * n_images, 32 * samples_per_image, 3))\n\n    row = 0\n    for images in dataset.repeat(samples_per_image).batch(n_images):\n        output[:, row*32:(row+1)*32] = np.vstack(images.numpy())\n        row += 1\n\n    plt.figure()\n    plt.imshow(output)\n    plt.show()\n\ndef flip(x: tf.Tensor) -> tf.Tensor:\n    \"\"\"Flip augmentation\n\n    Args:\n        x: Image to flip\n\n    Returns:\n        Augmented image\n    \"\"\"\n    x = tf.image.random_flip_left_right(x)\n    x = tf.image.random_flip_up_down(x)\n\n    return x\n\ndef color(x: tf.Tensor) -> tf.Tensor:\n    \"\"\"Color augmentation\n\n    Args:\n        x: Image\n\n    Returns:\n        Augmented image\n    \"\"\"\n    x = tf.image.random_hue(x, 0.08)\n    x = tf.image.random_saturation(x, 0.6, 1.6)\n    x = tf.image.random_brightness(x, 0.05)\n    x = tf.image.random_contrast(x, 0.7, 1.3)\n    return x\n\ndef rotate(x: tf.Tensor) -> tf.Tensor:\n    \"\"\"Rotation augmentation\n\n    Args:\n        x: Image\n\n    Returns:\n        Augmented image\n    \"\"\"\n\n    return tf.image.rot90(x, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n\ndef zoom(x: tf.Tensor) -> tf.Tensor:\n    \"\"\"Zoom augmentation\n\n    Args:\n        x: Image\n\n    Returns:\n        Augmented image\n    \"\"\"\n\n    # Generate 20 crop settings, ranging from a 1% to 20% crop.\n    scales = list(np.arange(0.8, 1.0, 0.01))\n    boxes = np.zeros((len(scales), 4))\n\n    for i, scale in enumerate(scales):\n        x1 = y1 = 0.5 - (0.5 * scale)\n        x2 = y2 = 0.5 + (0.5 * scale)\n        boxes[i] = [x1, y1, x2, y2]\n\n    def random_crop(img):\n        # Create different crops for an image\n        crops = tf.image.crop_and_resize([img], boxes=boxes, box_ind=np.zeros(len(scales)), crop_size=(32, 32))\n        # Return a random crop\n        return crops[tf.random_uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n\n\n    choice = tf.random_uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n\n    # Only apply cropping 50% of the time\n    return tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))\n\n#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n\ndata = (x_train[0:8] / 255).astype(np.float32)\ndataset = tf.data.Dataset.from_tensor_slices(data)\n\n# Add augmentations\naugmentations = [flip, color,rotate]\n\nfor f in augmentations:\n    dataset = dataset.map(lambda x: tf.cond(tf.random_uniform([], 0, 1) > 0.75, lambda: f(x), lambda: x), num_parallel_calls=4))\ndataset = dataset.map(lambda x: tf.clip_by_value(x, 0, 1))\n\nplot_images(dataset, n_images=4, samples_per_image=10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPooling2D,AveragePooling2D\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\n\n#------------------------------\n#variables\nnum_classes = 7 #angry, disgust, fear, happy, sad, surprise, neutral\nbatch_size = 256\nepochs =16\n#------------------------------\n\nwith open(\"../input/fer2013.csv\") as f:\n    content = f.readlines()\n\nlines = np.array(content)\n\nnum_of_instances = lines.size\nprint(\"number of instances: \",num_of_instances)\nprint(\"instance length: \",len(lines[1].split(\",\")[1].split(\" \")))\n\n#------------------------------\n#initialize trainset and test set\nx_train, y_train, x_test, y_test = [], [], [], []\n\n#------------------------------\n#transfer train and test set data\nfor i in range(1,num_of_instances):\n    try:\n        emotion, img, usage = lines[i].split(\",\")\n          \n        val = img.split(\" \")\n            \n        pixels = np.array(val, 'float32')\n        \n        emotion = tf.keras.utils.to_categorical(emotion, num_classes)\n    \n        if 'Training' in usage:\n            y_train.append(emotion)\n            x_train.append(pixels)\n        elif 'PublicTest' in usage:\n            y_test.append(emotion)\n            x_test.append(pixels)\n    except:\n        pass\n\t#print(\"\",end=\"\")\n\n\n\n\n#------------------------------\n#data transformation for train and test sets\nx_train = np.array(x_train, 'float32')\ny_train = np.array(y_train, 'float32')\nx_test = np.array(x_test, 'float32')\ny_test = np.array(y_test, 'float32')\n\nx_train /= 255 #normalize inputs between [0, 1]\nx_test /= 255\n\nx_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\nx_train = x_train.astype('float32')\nx_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\nx_test = x_test.astype('float32')\n\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n#------------------------------\n\n\n\n# Model\nmodel = Sequential()\n\n#1st convolution layer\nmodel.add(Conv2D(64, kernel_size=(5, 5),\n                 activation='relu',\n                 kernel_initializer='he_normal',\n                 input_shape=(48,48, 1)))\nmodel.add(MaxPooling2D(pool_size=(5, 5),strides=(2,2)))\n\n#2nd convolution layer\nmodel.add(Conv2D(64, \n                 kernel_size=(3, 3), \n                 activation='relu'))\nmodel.add(Conv2D(64, \n                 kernel_size=(3, 3), \n                 activation='relu'))\nmodel.add(AveragePooling2D(pool_size=(3, 3),strides=(2,2)))\n\n#3rd convolution layer\nmodel.add(Conv2D(128, \n                 kernel_size=(3, 3), \n                 activation='relu'))\nmodel.add(Conv2D(128, \n                 kernel_size=(3, 3), \n                 activation='relu'))\nmodel.add(AveragePooling2D(pool_size=(3, 3),strides=(2,2)))\n\n\nmodel.add(Flatten())\n#fully connected neural networks\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\n\n\n\n'''\ngen = ImageDataGenerator()\ntrain_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n\n'''\n\n\n'''\n# data preprocessing\ndef data_preprocessing(raw):\n    out_y = keras.utils.to_categorical(raw.label, NUM_CLASSES)\n    num_images = raw.shape[0]\n    x_as_array = raw.values[:,1:]\n    x_shaped_array = x_as_array.reshape(num_images, IMG_ROWS, IMG_COLS, 1)\n    out_x = x_shaped_array / 255\n    return out_x, out_y\n    \n# prepare the data\nX, y = data_preprocessing(train_data)\nX_test, y_test = data_preprocessing(test_data)\n\n'''\nX_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3)\n\nmodel.fit(X_train, y_train,\n                  batch_size=256,\n                  epochs=32,\n                  verbose=1,\n                  validation_data=(X_val, y_val))\n\nimport os\n\nfile_path = \"../output\"\ndirectory = os.path.dirname(file_path)\n\ntry:\n    os.stat(directory)\nexcept:\n    os.mkdir(directory)\n\n\n# Save tf.keras model in HDF5 format.\nkeras_file = \"keras_model.h5\"\ntf.keras.models.save_model(model, keras_file)\n\n# Convert to TensorFlow Lite model.\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)\ntflite_model = converter.convert()\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\n\n\nprint('done !')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#batch process\n\n\n'''\n\n# Define parameters\nbatch_size = 128\n\n# Get data\nfashion_mnist = keras.datasets.mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n\n# Create tf dataset\nwith tf.variable_scope(\"DataPipe\"):\n    dataset = tf.data.Dataset.from_tensor_slices(train_images)\n    dataset = dataset.map(lambda x: tf.image.convert_image_dtype([x], dtype=tf.float32))\n    dataset = dataset.batch(batch_size=batch_size).prefetch(batch_size)\n\n    iterator = dataset.make_initializable_iterator()\n    input_batch = iterator.get_next()\n    input_batch = tf.reshape(input_batch, shape=[-1, 28, 28, 1])\n\n'''\n\n\ngen = ImageDataGenerator()\ntrain_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n\n#------------------------------\n\nmodel.compile(loss='categorical_crossentropy'\n    , optimizer=keras.optimizers.Adam()\n    , metrics=['accuracy']\n)\n\n#------------------------------\n\nfit = True\nhistory=None\nif fit == True:\n\t#model.fit_generator(train_generator, epochs=epochs) #train for all trainset\n    #history = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n\thistory=model.fit_generator(train_generator,steps_per_epoch=batch_size, epochs=5) #train for randomly selected one\nelse:\n\tmodel.load_weights('..input/model_weights.h5') #load weights\n\t\n#------------------------------\n\n#overall evaluation\nscore = model.evaluate(x_test, y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', 100*score[1])\n\n#------------------------------\n#function for drawing bar chart for emotion preditions\ndef emotion_analysis(emotions):\n    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n    y_pos = np.arange(len(objects))\n    \n    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n    plt.xticks(y_pos, objects)\n    plt.ylabel('percentage')\n    plt.title('emotion')\n    \n    plt.show()\n#------------------------------\n\nmonitor_testset_results = False\n\nif monitor_testset_results == True:\n\t#make predictions for test set\n\tpredictions = model.predict(x_test)\n\n\tindex = 0\n\tfor i in predictions:\n\t\tif index < 30 and index >= 20:\n\t\t\t#print(i) #predicted scores\n\t\t\t#print(y_test[index]) #actual scores\n\t\t\t\n\t\t\ttesting_img = np.array(x_test[index], 'float32')\n\t\t\ttesting_img = testing_img.reshape([48, 48]);\n\t\t\t\n\t\t\tplt.gray()\n\t\t\tplt.imshow(testing_img)\n\t\t\tplt.show()\n\t\t\t\n\t\t\tprint(i)\n\t\t\t\n\t\t\temotion_analysis(i)\n\t\t\tprint(\"----------------------------------------------\")\n\t\tindex = index + 1\n\n\n        \n        #-----------------\n#------------------------------\nimport os\n\nfile_path = \"../output\"\ndirectory = os.path.dirname(file_path)\n\ntry:\n    os.stat(directory)\nexcept:\n    os.mkdir(directory)\n\n\n# Save tf.keras model in HDF5 format.\nkeras_file = \"keras_model.h5\"\ntf.keras.models.save_model(model, keras_file)\n\n# Convert to TensorFlow Lite model.\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)\ntflite_model = converter.convert()\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.layers import Dense, Activation, Dropout, Flatten\n\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n#------------------------------\n#variables\nnum_classes = 7 #angry, disgust, fear, happy, sad, surprise, neutral\nbatch_size = 256\nepochs =16\n#------------------------------\n\nwith open(\"../input/fer2013.csv\") as f:\n    content = f.readlines()\n\nlines = np.array(content)\n\nnum_of_instances = lines.size\nprint(\"number of instances: \",num_of_instances)\nprint(\"instance length: \",len(lines[1].split(\",\")[1].split(\" \")))\n\n#------------------------------\n#initialize trainset and test set\nx_train, y_train, x_test, y_test = [], [], [], []\n\n#------------------------------\n#transfer train and test set data\nfor i in range(1,num_of_instances):\n    try:\n        emotion, img, usage = lines[i].split(\",\")\n          \n        val = img.split(\" \")\n            \n        pixels = np.array(val, 'float32')\n        \n        emotion = keras.utils.to_categorical(emotion, num_classes)\n    \n        if 'Training' in usage:\n            y_train.append(emotion)\n            x_train.append(pixels)\n        elif 'PublicTest' in usage:\n            y_test.append(emotion)\n            x_test.append(pixels)\n    except:\n        pass\n\t#print(\"\",end=\"\")\n\n#------------------------------\n#data transformation for train and test sets\nx_train = np.array(x_train, 'float32')\ny_train = np.array(y_train, 'float32')\nx_test = np.array(x_test, 'float32')\ny_test = np.array(y_test, 'float32')\n\nx_train /= 255 #normalize inputs between [0, 1]\nx_test /= 255\n\nx_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\nx_train = x_train.astype('float32')\nx_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\nx_test = x_test.astype('float32')\n\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n#------------------------------\n#construct CNN structure\nmodel = Sequential()\n\n#1st convolution layer\nmodel.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\nmodel.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n\n#2nd convolution layer\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n\n#3rd convolution layer\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n\nmodel.add(Flatten())\n\n#fully connected neural networks\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(num_classes, activation='softmax'))\n#------------------------------\n#batch process\ngen = ImageDataGenerator()\ntrain_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n\n#------------------------------\n\nmodel.compile(loss='categorical_crossentropy'\n    , optimizer=keras.optimizers.Adam()\n    , metrics=['accuracy']\n)\n\n#------------------------------\n\nfit = True\nhistory=None\nif fit == True:\n\t#model.fit_generator(train_generator, epochs=epochs) #train for all trainset\n    #history = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n\thistory=model.fit_generator(train_generator,steps_per_epoch=batch_size, epochs=5) #train for randomly selected one\nelse:\n\tmodel.load_weights('..input/model_weights.h5') #load weights\n\t\n#------------------------------\n\n#overall evaluation\nscore = model.evaluate(x_test, y_test)\nprint('Test loss:', score[0])\nprint('Test accuracy:', 100*score[1])\n\n#------------------------------\n#function for drawing bar chart for emotion preditions\ndef emotion_analysis(emotions):\n    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n    y_pos = np.arange(len(objects))\n    \n    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n    plt.xticks(y_pos, objects)\n    plt.ylabel('percentage')\n    plt.title('emotion')\n    \n    plt.show()\n#------------------------------\n\nmonitor_testset_results = False\n\nif monitor_testset_results == True:\n\t#make predictions for test set\n\tpredictions = model.predict(x_test)\n\n\tindex = 0\n\tfor i in predictions:\n\t\tif index < 30 and index >= 20:\n\t\t\t#print(i) #predicted scores\n\t\t\t#print(y_test[index]) #actual scores\n\t\t\t\n\t\t\ttesting_img = np.array(x_test[index], 'float32')\n\t\t\ttesting_img = testing_img.reshape([48, 48]);\n\t\t\t\n\t\t\tplt.gray()\n\t\t\tplt.imshow(testing_img)\n\t\t\tplt.show()\n\t\t\t\n\t\t\tprint(i)\n\t\t\t\n\t\t\temotion_analysis(i)\n\t\t\tprint(\"----------------------------------------------\")\n\t\tindex = index + 1\n\n\n        \n        #-----------------\n#------------------------------\nimport os\n\nfile_path = \"../output\"\ndirectory = os.path.dirname(file_path)\n\ntry:\n    os.stat(directory)\nexcept:\n    os.mkdir(directory)\n\n'''\n# serialize model to JSON\nmodel_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n\n\n'''\nimport tensorflow as tf\n\n\n# Save tf.keras model in HDF5 format.\nkeras_file = \"keras_model.h5\"\nmodel.save_weights(keras_file)\n\n# Convert to TensorFlow Lite model.\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)\ntflite_model = converter.convert()\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\n \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9b94789cb763a65b6f828677f091e093a353b61"},"cell_type":"code","source":"%matplotlib inline\n\n\n\nmodel.summary()\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test.argmax(axis=1),model.predict(x_test).argmax(axis=1))\n\n\n\n#visualise the history\n# list all data in history\nprint(history.history.keys())\n\n# summarize history for loss and acc\nplt.plot(history.history['loss'])\nplt.plot(history.history['acc'])\nplt.title('model loss and accuracy ')\nplt.ylabel('loss')\nplt.xlabel('acc')\nplt.legend(['loss', 'accuracy'], loc='upper left')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33886f947ade51f56d20fd7eb265941df1aebf87"},"cell_type":"code","source":"# summarize history for loss\nplt.plot(history.history['loss'])\n#plt.plot(epochs)\nplt.title('model loss with respect to epochs ')\nplt.ylabel('loss')\nplt.xlabel('epochs')\nplt.legend(['loss', 'epochs'], loc='upper left')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e847b19b0e58fb77b1a7384b710421fa4727825"},"cell_type":"code","source":"# summarize history for loss\nplt.plot(history.history['acc'])\n#plt.plot([4,8,12,16])\nplt.title('model accuracy with respect to epochs ')\nplt.ylabel('accuracy')\nplt.xlabel('epochs')\nplt.legend(['acc', 'epochs'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfb8307a53ac312f37433f0136b443da79c5f2f5"},"cell_type":"code","source":"from keras.callbacks import Callback\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\ndef output_sensitivity_specificity(epoch, predictions, y_test, mode='binary'):\n    if mode == 'binary':\n        # determine positive class predictions\n        idx = predictions >= 0.5\n        predictions = np.zeros(predictions.shape)\n        predictions[idx] = 1\n        # no need to modify y_test since it consists of zeros and ones already\n    else:\n        y_test = np.argmax(y_test, axis=-1)\n        predictions = np.argmax(predictions, axis=-1)\n\n    c = confusion_matrix(y_test, predictions)\n    print('Confusion matrix:\\n', c)\n    print('[{:03d}] sensitivity'.format(epoch), c[0, 0] / (c[0, 1] + c[0, 0]))\n    print('[{:03d}] specificity'.format(epoch), c[1, 1] / (c[1, 1] + c[1, 0]))\n    \n    \n    \n    \noutput_sensitivity_specificity(epochs, predictions, y_test, mode='categorical_crossentropy')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}